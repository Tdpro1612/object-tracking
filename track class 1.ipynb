{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bản sao của new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eiLDW1fxaSF"
      },
      "source": [
        "\n",
        "Lời giải cơ bản cho cuộc thi\n",
        "Đây là hướng dẫn một phương pháp cơ bản dùng để phát hiện hướng di chuyển (MOI) của phương tiện giao thông trong vùng trong vùng quan sát (ROI) cùng thời điểm phương tiện rời khỏi ROI.\n",
        "\n",
        "Hướng dẫn này sử dụng các mã nguồn mở từ các nguồn sau:\n",
        "\n",
        "TensorFlow Object Detection API\n",
        "\n",
        "Simple online and realtime tracking\n",
        "\n",
        "Tổng quan phương pháp cơ bản được trình bày như sau:\n",
        "\n",
        "Phát hiện phương tiện giao thông trong từng frame của video: Sử dụng TensorFlow Object Detection API. Kết quả trả về là một danh sách các bounding box ứng với tất cả các phương tiện giao thông trong ảnh.\n",
        "Theo vết (multiple objects tracking): Dựa vào IOU (chỉ số đo đạc mức độ trùng lắp của hai bounding box), các bounding box ở các frame liên tiếp sẽ được gom nhóm và từ đó sẽ hình thành quỹ đạo di chuyển của chính phương tiện đó.\n",
        "Xác định hướng di chuyển (MOI) dựa trên quỹ đạo: MOI của phương tiện sẽ được lựa chọn dựa trên độ tương đồng (ở đây sử dụng Cosine Similarity Score) giữa quỹ đạo của mỗi phương tiện và các MOI sẽ được tính toán.\n",
        "Lưu ý: Trong lời giải cơ bản này, chỉ minh họa việc phát hiện và đếm phương tiện xe máy. Bạn cần chỉnh sửa và cải tiến để có thể đếm được tất cả phương tiện giao thông mà đề bài yêu cầu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUqh0EH8xes7"
      },
      "source": [
        "#Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhzbPymixiva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c080a9-c776-4fe9-d1cb-5cdbe82e5b4b"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.2.0\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.35.1)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.10.0)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 36.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuG3FgODxtzK"
      },
      "source": [
        "##Cấu hình thư mục lưu trữ dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjQGKE7SxmPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9abd01c-4a4a-4219-efd7-2a6e8b33f44f"
      },
      "source": [
        "# Mount \"My Drive\" into /content/drive\n",
        "from google.colab import drive\n",
        "\n",
        "#google_drive_dir = 'Shared/HCMCAIC'  # @param\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#mount_point = '/content/drive/My Drive/{}'.format(google_drive_dir)\n",
        "\n",
        "# Change the root directory to your mount_point\n",
        "#% cd '$mount_point'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KReqdID6yCdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8537421-eafe-4f96-8dbd-5fa96f6e38d5"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the baseline repository \n",
        "if not pathlib.Path('ai-challenge-baseline').exists():\n",
        "  ! git clone https://github.com/hcmcaic/ai-challenge-baseline\n",
        "\n",
        "# \n",
        "% cd ai-challenge-baseline\n",
        "\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ai-challenge-baseline'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 40 (delta 9), reused 26 (delta 7), pack-reused 11\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n",
            "/content/ai-challenge-baseline\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2301, done.\u001b[K\n",
            "remote: Counting objects: 100% (2301/2301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1993/1993), done.\u001b[K\n",
            "remote: Total 2301 (delta 563), reused 949 (delta 285), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2301/2301), 30.57 MiB | 31.91 MiB/s, done.\n",
            "Resolving deltas: 100% (563/563), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy6pJ9IIyFZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dddc052-4bf5-4452-8c30-88cd821d2b97"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/ai-challenge-baseline/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/5a/819537be46d65a01f8b8c6046ed05603fb9ef88c663b8cca840263788d58/avro-python3-1.10.0.tar.gz\n",
            "Collecting apache-beam\n",
            "  Downloading https://files.pythonhosted.org/packages/86/3f/93816e989e8e59b337f22927778494a99b2a3e78a3b6a9e34d043c6fab4e/apache_beam-2.25.0-cp36-cp36m-manylinux2010_x86_64.whl (8.7MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.4)\n",
            "Collecting tf-models-official\n",
            "  Downloading https://files.pythonhosted.org/packages/5b/33/91e5e90e3e96292717245d3fe87eb3b35b07c8a2113f2da7f482040facdb/tf_models_official-2.3.0-py2.py3-none-any.whl (840kB)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Collecting pyarrow<0.18.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\"\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/3f/6cac1714fff444664603f92cb9fbe91c7ae25375880158b9e9691c4584c8/pyarrow-0.17.1-cp36-cp36m-manylinux2014_x86_64.whl (63.8MB)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.33.2)\n",
            "Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading https://files.pythonhosted.org/packages/af/54/1054887181f600414beba751290fe13dfa44214e91397aa0c867adb7d74b/fastavro-1.1.0-cp36-cp36m-manylinux2014_x86_64.whl (2.0MB)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting mock<3.0.0,>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz (41kB)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (50.3.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n",
            "Collecting tensorflow>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/ad/769c195c72ac72040635c66cd9ba7b0f4b4fc1ac67e59b99fa6988446c22/tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading https://files.pythonhosted.org/packages/08/e9/57d869561389884136be65a2d1bc038fe50171e2ba348fda269a4aab8032/opencv_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (36.7MB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Collecting pbr>=0.11\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.6.20)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->tf-models-official->object-detection==0.1) (0.1.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.24.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.35.1)\n",
            "Collecting tensorboard<3,>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/1b/6a420d7e6ba431cf3d51b2a5bfa06a958c4141e3189385963dc7f6fbffb6/tensorboard-2.3.0-py3-none-any.whl (6.8MB)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (0.0.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, future, hdfs, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1598322 sha256=320651326b8f185035035b44b580e62c9984798f94eef722c003b65040437429\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tzm59msk/wheels/2e/a7/0f/dae5f4550c548021aa2a057c6f045005a043a0898b4353b392\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.0-cp36-none-any.whl size=43735 sha256=e594ee254e9f10878df252a600d3441bd04d27c6be79b494f9e691b7c091a1f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/15/cd/fe4ec8b88c130393464703ee8111e2cddebdc40e1b59ea85e9\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78532 sha256=89391015ffb3262133bdc94cc14262c176a1f8f3bcd8e6477b70e1c6bf1e0e92\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=94afb9c3d399f0212bb7bd7f25e904ea99bf7ee3dba17f261c99ddeeafd79207\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for hdfs (setup.py): started\n",
            "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
            "  Created wheel for hdfs: filename=hdfs-2.5.8-cp36-none-any.whl size=33213 sha256=079c880ceda8ac4529f060c09b1a973387f11398c39c8d3d2a718a38bca06494\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20071 sha256=3b29e162476b214f8b8803acfd70c7ab7eb1453855a1ebd09b8ef78a85a2108d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
            "Successfully built object-detection avro-python3 dill future hdfs py-cpuinfo\n",
            "Installing collected packages: avro-python3, dill, pyarrow, fastavro, future, pbr, mock, requests, hdfs, apache-beam, tf-slim, lvis, tensorflow-model-optimization, py-cpuinfo, tensorboard, tensorflow-estimator, tensorflow, sentencepiece, opencv-python-headless, tf-models-official, object-detection\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed apache-beam-2.25.0 avro-python3-1.10.0 dill-0.3.1.1 fastavro-1.1.0 future-0.18.2 hdfs-2.5.8 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.4.0.46 pbr-5.5.1 py-cpuinfo-7.0.0 pyarrow-0.17.1 requests-2.24.0 sentencepiece-0.1.94 tensorboard-2.3.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 tensorflow-model-optimization-0.5.0 tf-models-official-2.3.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.3.1.1 which is incompatible.\n",
            "ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\n",
            "ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "ERROR: apache-beam 2.25.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1; python_version >= \"3.0\", but you'll have avro-python3 1.10.0 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkG7bpyGyreb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783a820c-eb36-40bd-88bd-ff069130aada"
      },
      "source": [
        "# Install the requirements package for SORT source code\n",
        "! pip install filterpy scikit-image lap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting filterpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/ac8914360460fafa1990890259b7fa5ef7ba4cd59014e782e4ab3ab144d8/filterpy-1.4.5.zip (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
            "Collecting lap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from filterpy) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.5)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy) (1.15.0)\n",
            "Building wheels for collected packages: filterpy, lap\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-cp36-none-any.whl size=110450 sha256=4131a95b08b4e558c606fd51e708a6f7aa2f86949470416a9619b01ef239006a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/0c/dd/e92392c3f38a41371602d99fc77d6c1d42aadbf0c6afccdd02\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp36-cp36m-linux_x86_64.whl size=1589021 sha256=d1ea4aac6334020be47c991b91bca583c2b7e1ceb8e8beac00029a7fb55fbcb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/3e/af/eddcd6ffaa27df8d0ddac573758f8953c4e57c64c4c8c8b7d0\n",
            "Successfully built filterpy lap\n",
            "Installing collected packages: filterpy, lap\n",
            "Successfully installed filterpy-1.4.5 lap-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGlBdmhHyvP7"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwOtDNFQy5Cy"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def get_keypoint_tuples(eval_config):\n",
        "  \"\"\"Return a tuple list of keypoint edges from the eval config.\n",
        "  \n",
        "  Args:\n",
        "    eval_config: an eval config containing the keypoint edges\n",
        "  \n",
        "  Returns:\n",
        "    a list of edge tuples, each in the format (start, end)\n",
        "  \"\"\"\n",
        "  tuple_list = []\n",
        "  kp_list = eval_config.keypoint_edge\n",
        "  for edge in kp_list:\n",
        "    tuple_list.append((edge.start, edge.end))\n",
        "  return tuple_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNJ49BVSBzFz"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "\n",
        "class Detector(object):\n",
        "    def __init__(self, path_config, path_ckpt, path_to_labels):\n",
        "        self.path_config = path_config\n",
        "        self.path_ckpt = path_ckpt\n",
        "        self.label_path = path_to_labels\n",
        "\n",
        "        self.category_index = label_map_util.create_category_index_from_labelmap(path_to_labels, use_display_name=True)\n",
        "        self.detection_model = self.load_model()\n",
        "        self.detection_scores = None\n",
        "        self.detection_boxes = None\n",
        "        self.detection_classes = None\n",
        "\n",
        "    def detect_fn(self, image):\n",
        "        \"\"\"Detect objects in image.\"\"\"\n",
        "        image, shapes = self.detection_model.preprocess(image)\n",
        "        prediction_dict = self.detection_model.predict(image, shapes)\n",
        "        detections = self.detection_model.postprocess(prediction_dict, shapes)\n",
        "        return detections\n",
        "\n",
        "    def load_model(self):\n",
        "        # Load pipeline config and build a detection model\n",
        "        configs = config_util.get_configs_from_pipeline_file(self.path_config)\n",
        "        model_config = configs['model']\n",
        "        detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "        # Restore checkpoint\n",
        "        ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "        ckpt.restore(self.path_ckpt).expect_partial()\n",
        "\n",
        "        return detection_model\n",
        "\n",
        "    def predict(self, image):\n",
        "        original_img = np.copy(image)\n",
        "\n",
        "        image = np.asarray(image)\n",
        "\n",
        "        input_tensor = tf.convert_to_tensor(np.expand_dims(image, 0), dtype=tf.float32)\n",
        "        detections = self.detect_fn(input_tensor)\n",
        "\n",
        "        # All outputs are batches tensors.\n",
        "        # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "        # We're only interested in the first num_detections.\n",
        "        num_detections = int(detections.pop('num_detections'))\n",
        "        # num_detections = int(detections.pop('num_detections'))\n",
        "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
        "        detections['num_detections'] = num_detections\n",
        "\n",
        "        # detection_classes should be ints.\n",
        "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "        self.detection_scores = detections['detection_scores']\n",
        "        self.detection_classes = detections['detection_classes']\n",
        "        self.detection_boxes = detections['detection_boxes']\n",
        "\n",
        "        # draw bounding boxes and labels\n",
        "        image, coordinate_dict = self.draw(image)\n",
        "\n",
        "        return image, original_img, coordinate_dict\n",
        "\n",
        "    def draw(self, img):\n",
        "        coordinate_dict = dict()\n",
        "        height, width, _ = img.shape\n",
        "        li = []\n",
        "\n",
        "        for i, score in enumerate(self.detection_scores):\n",
        "            self.detection_classes[i] += 1\n",
        "            # if background, ignore\n",
        "            # if self.detection_classes[i] == 0:\n",
        "            #     continue\n",
        "            # if self.detection_classes[i] != 3 and self.detection_classes[i] != 4 and self.detection_classes[i] != 6 and self.detection_classes[i] != 8:\n",
        "            #     continue\n",
        "            # If class is motorcycle \n",
        "            if self.detection_classes[i] == 1:\n",
        "                if score < 0.3:\n",
        "                  continue\n",
        "            \n",
        "            print(\"Index {} at score {} and class {} \".format(i , score, self.detection_classes[i]))                        \n",
        "            label = \"index \" + str(i) + \" class \" + str(self.category_index[self.detection_classes[i]]['name']) \n",
        "            ymin, xmin, ymax, xmax = self.detection_boxes[i]\n",
        "            real_xmin, real_ymin, real_xmax, real_ymax = int(xmin * width), int(ymin * height), int(xmax * width), int(\n",
        "                ymax * height)\n",
        "\n",
        "            #curr = real_xmax * real_ymax - real_ymin * real_xmin\n",
        "            curr_bb = {\"xmin\" : real_xmin , \"xmax\" : real_xmax , \"ymin\" : real_ymin , \"ymax\" :real_ymax }\n",
        "            status = is_overlap(curr_bb, li)\n",
        "            if status == 1:\n",
        "                continue\n",
        "            print(\"Is not ovelaped\")\n",
        "            li.append(curr_bb)\n",
        "            # check overlap bounding boxes\n",
        "\n",
        "            cv2.rectangle(img, (real_xmin, real_ymin), (real_xmax, real_ymax), (0, 255, 0), 2)\n",
        "            cv2.putText(img, label, (real_xmin, real_ymin), cv2.FONT_HERSHEY_SIMPLEX, color=(0, 0, 255), fontScale=0.5)\n",
        "            coordinate_dict[label] = (real_xmin, real_ymin, real_xmax, real_ymax)\n",
        "\n",
        "        return img, coordinate_dict\n",
        "\n",
        "def get_IOU(bb1 , bb2):\n",
        "    x_left = max(bb1['xmin'], bb2['xmin'])\n",
        "    y_top = max(bb1['ymin'], bb2['ymin'])\n",
        "    x_right = min(bb1['xmax'], bb2['xmax'])\n",
        "    y_bottom = min(bb1['ymax'], bb2['ymax'])\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "    bb1_area = (bb1['xmax'] - bb1['xmin']) * (bb1['ymax'] - bb1['ymin'])\n",
        "    bb2_area = (bb2['xmax'] - bb2['xmin']) * (bb2['ymax'] - bb2['ymin'])\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0\n",
        "    assert iou <= 1\n",
        "    return iou\n",
        "\n",
        "def is_overlap(bb , list_bounding_box):\n",
        "    for bounding_box in list_bounding_box:\n",
        "        if (get_IOU(bb , bounding_box) > 0.5):\n",
        "          return 1\n",
        "    return 0\n",
        "\n",
        "def check_overlap(curr, li):\n",
        "    for va in li:\n",
        "        # overlap\n",
        "        if abs(va - curr) < 1000:\n",
        "            return 1\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jvo_vxOzoiC"
      },
      "source": [
        "import json\n",
        "def load_zone_anno(json_filename):\n",
        "  \"\"\"\n",
        "  Load the json with ROI and MOI annotation.\n",
        "\n",
        "  \"\"\"\n",
        "  with open(json_filename) as jsonfile:\n",
        "    dd = json.load(jsonfile)\n",
        "    polygon = [(int(x), int(y)) for x, y in dd['shapes'][0]['points']]\n",
        "    paths = {}\n",
        "    for it in dd['shapes'][1:]:\n",
        "      kk = str(int(it['label'][-2:]))\n",
        "      paths[kk] = [(int(x), int(y)) for x, y\n",
        "              in it['points']]\n",
        "  return polygon, paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktteYSvlzr5x"
      },
      "source": [
        "polygon, paths = load_zone_anno('/content/drive/My Drive/zones_movement_paths/cam_06.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K5u-yLrB5Ti"
      },
      "source": [
        "%cd '/content/ai-challenge-baseline'\n",
        "from solution_baseline import bb_polygon\n",
        "def check_bbox_intersect_polygon(polygon, bbox):\n",
        "  \"\"\"\n",
        "  \n",
        "  Args:\n",
        "    polygon: List of points (x,y)\n",
        "    bbox: A tuple (xmin, ymin, xmax, ymax)\n",
        "  \n",
        "  Returns:\n",
        "    True if the bbox intersect the polygon\n",
        "  \"\"\"\n",
        "  x1, y1, x2, y2 = bbox\n",
        "  bb = [(x1,y1), (x2, y1), (x2,y2), (x1,y2)]\n",
        "  return bb_polygon.is_bounding_box_intersect(bb, polygon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZdm7czoB7KS"
      },
      "source": [
        "detector = Detector('/content/drive/My Drive/class1_only_v2/pipeline.config'\n",
        "                    ,'/content/drive/My Drive/class1_only_v2/checkpoint/ckpt-0'\n",
        "                    ,'/content/drive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHXUlqbEB74r"
      },
      "source": [
        "image_dir = '/content/drive/My Drive/Frames/cam_06'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejr9DnjtCAd6"
      },
      "source": [
        "from solution_baseline.sort import *\n",
        "moto_tracker = Sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzYIEo4nynU1"
      },
      "source": [
        "import time\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyq2jyZgCCLE"
      },
      "source": [
        "# Create an motobikes tracker with default parameter.\n",
        "# Please read the sort documentation for the custom paramenters.\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "moto_tracker = Sort()\n",
        "\n",
        "# If you want to track another vehicle class, you need to declare a new tracker.\n",
        "# truck_tracker = Sort()\n",
        "\n",
        "\n",
        "track_dict_moto = {}\n",
        "\n",
        "N_FRAMES = 6010\n",
        "\n",
        "#print(\"running\")\n",
        "for frame_id in tqdm(range(0, N_FRAMES ,1)):\n",
        "  if frame_id % 10 == 0:\n",
        "    clear_output(wait=True)\n",
        "  image_path = os.path.join(image_dir, '{}.jpg'.format(frame_id))\n",
        "  # print(\"Image path :\")\n",
        "  \n",
        "  if not os.path.isfile(image_path):\n",
        "    continue\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "  # track_image_for_bus = image_np.copy()\n",
        "  # track_image_for_car = image_np.copy()\n",
        "  # track_image_for_moto = image_np.copy()\n",
        "\n",
        "  im_width, im_height, _ = image_np.shape\n",
        "  input_tensor = tf.convert_to_tensor(\n",
        "      np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "  #detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "  #image, original_image, coordinate_dict = detector.predict(image_np)\n",
        "  #cv2_imshow(image)\n",
        "\n",
        "  # print(\"Visualize after get tracker\")\n",
        "  detections = detector.detect_fn(input_tensor)\n",
        "\n",
        "  boxes = detections['detection_boxes'][0]\n",
        "  scores = detections['detection_scores'][0]\n",
        "  classes = detections['detection_classes'][0]\n",
        "\n",
        "\n",
        "  dets_moto = []\n",
        "  #count = -1\n",
        "  for bb, s, c in zip(boxes, scores, classes):\n",
        "    num_class = c + 1\n",
        "    #count = count + 1\n",
        "    if num_class == 1:\n",
        "      if s < 0.3:\n",
        "        continue  \n",
        "    \n",
        "    ymin, xmin, ymax, xmax = bb.numpy()\n",
        "    xmin, ymin, xmax, ymax = int(xmin*im_height), int(ymin*im_width), int(xmax*im_height), int(ymax*im_width)\n",
        "    if check_bbox_intersect_polygon(polygon, (xmin, ymin, xmax, ymax)):\n",
        "      #print(\"index {} class {} Is intersect  ROI\".format(count , num_class))\n",
        "     \n",
        "      if num_class == 1:\n",
        "        dets_moto.append([xmin, ymin, xmax, ymax, s.numpy()])\n",
        "    #else :\n",
        "      #print(\"index {} class {} Is not intersect of ROI\".format(count , num_class))\n",
        "\n",
        "\n",
        "\n",
        "  dets_moto = np.array(dets_moto)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "  if dets_moto.size != 0:\n",
        "    trackers_moto = moto_tracker.update(dets_moto)\n",
        "  # print('trackers')\n",
        "  # print(trackers)\n",
        "\n",
        "    for xmin, ymin, xmax, ymax, track_id in trackers_moto:\n",
        "      track_id = int(track_id)\n",
        "      #  Visualize tracker\n",
        "      #cv2.rectangle(track_image_for_moto, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
        "      #cv2.putText(track_image_for_moto, \"Moto Track \" + str(track_id), (int(xmax), int(ymax)), cv2.FONT_HERSHEY_SIMPLEX, color=(0, 0, 255), fontScale=0.5)\n",
        "      ##print(track_id)\n",
        "      if track_id not in track_dict_moto.keys():\n",
        "        track_dict_moto[track_id] = [(xmin, ymin, xmax, ymax, frame_id)]\n",
        "      else:\n",
        "        track_dict_moto[track_id].append((xmin, ymin, xmax, ymax, frame_id))\n",
        "    # print(\"Trackdict\")\n",
        "    # print(track_dict)\n",
        "    #print(\"Track number in moto: {}\".format(len(track_dict_moto.keys())))\n",
        "    #cv2_imshow(track_image_for_moto) \n",
        "\n",
        "\n",
        "#print(\"Finished\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e6IoLH7CCSw"
      },
      "source": [
        "# moto_vector_list: list of tuples (first_point, last_point, last_frame_id)\n",
        "# list of moto movement vector and the last frame_id when it is still in the ROI.\n",
        "\n",
        "moto_vector_list = []\n",
        "for tracker_id, tracker_list in track_dict_moto.items():\n",
        "  # print(track_id)\n",
        "  if len(tracker_list) > 1:\n",
        "    first = tracker_list[0]\n",
        "    last = tracker_list[-1]\n",
        "    first_point = ((first[2] - first[0])/2, (first[3] - first[1])/2)\n",
        "    last_point = ((last[2] - last[0])/2, (last[3] - last[1])/2)\n",
        "    moto_vector_list.append((first_point, last_point, last[4]))\n",
        "    a = [first_point, last_point, last[4]]\n",
        "    # print(a)\n",
        "    \n",
        "# print(moto_vector_list)  \n",
        "# print(type(moto_vector_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY0SsHk3CINL"
      },
      "source": [
        "def cosin_similarity(a2d, b2d):\n",
        "  \n",
        "  a = np.array((a2d[1][0] - a2d[0][0], a2d[1][1 ]- a2d[0][1]))\n",
        "  b = np.array((b2d[1][0] - b2d[0][1], b2d[1][1] - b2d[1][0]))\n",
        "  return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIV45f_uCMii"
      },
      "source": [
        "MOTO_CLASS_ID = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueLoXVKACLzC"
      },
      "source": [
        "def counting_moi(paths, moto_vector_list):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    paths: List of MOI - (first_point, last_point)\n",
        "    moto_vector_list: List of tuples (first_point, last_point, last_frame_id) \n",
        "  \n",
        "  Returns:\n",
        "    A list of tuples (frame_id, movement_id, vehicle_class_id)\n",
        "  \"\"\"\n",
        "  moi_detection_list = []\n",
        "  for moto_vector in moto_vector_list:\n",
        "    max_cosin = -2\n",
        "    movement_id = ''\n",
        "    last_frame = 0\n",
        "    for movement_label, movement_vector in paths.items():\n",
        "      cosin = cosin_similarity(movement_vector, moto_vector)\n",
        "      if cosin > max_cosin:\n",
        "        max_cosin = cosin\n",
        "        movement_id = movement_label\n",
        "        last_frame = moto_vector[2]\n",
        "\n",
        "    moi_detection_list.append((last_frame, movement_id, MOTO_CLASS_ID))\n",
        "  return moi_detection_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOMbCaraCQmb"
      },
      "source": [
        "moto_moi_detections = counting_moi(paths, moto_vector_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UX7pGbiCRwq"
      },
      "source": [
        "result_filename = 'cam_06.txt'\n",
        "video_id = 'cam_06'\n",
        "with open(result_filename, 'w') as result_file:\n",
        "  for frame_id, movement_id, vehicle_class_id in moto_moi_detections:\n",
        "    result_file.write('{} {} {} {}\\n'.format(video_id, frame_id, movement_id, vehicle_class_id))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}